{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15 â€“ Weather Prediction\n",
    "### <font color=blue>Traditional Linear Model that predicts temperature(s) using previous temperatures data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#sklearn imports\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to verify the existence of a file in the current working directory and download it if not\n",
    "import os,urllib, urllib.request, sys, tarfile\n",
    "def downloadDataResource(file, sourcePath, compressed=None):\n",
    "    if not os.path.isfile(file):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(sourcePath+(compressed if compressed else file),(compressed if compressed else file))\n",
    "            print(\"Downloaded\", (compressed if compressed else file) )\n",
    "            if compressed:\n",
    "                ucomp = tarfile.open(compressed)\n",
    "                ucomp.extractall()\n",
    "                ucomp.close()\n",
    "                print(\"File uncompressed.\")\n",
    "        except:\n",
    "            print(\"ERROR: File\", (compressed if compressed else file), \"not found. Data source missing.\")\n",
    "    else:\n",
    "        print(\"Data resource\", file, \"already downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function provided that plots the learning curve for neural networks\n",
    "def nn_plot_learning_curve( history ):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    ymin, ymax = [], []\n",
    "    for x in history.history.keys():\n",
    "        ymax.append( max(history.history[x]))\n",
    "        ymin.append( min(history.history[x]))\n",
    "    plt.gca().set_ylim(min(ymin)*.95, max(ymax)*1.05)\n",
    "    plt.xlabel(\"EPOCHS\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot actual values vs. predicted values\n",
    "def plot_actual_pred( actual, prediction ):\n",
    "    plt.plot(actual, \".-\", alpha=.6, label=\"Actual\")\n",
    "    plt.plot(prediction, \".-\", alpha=.6, label=\"Prediction\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that shows a learning curve for any model that has predict or fit methods\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator,X,y,ylim=None,cv=None,n_jobs=None,train_sizes=np.linspace(0.1, 1.0, 20),scoring = 'neg_root_mean_squared_error'):\n",
    "    \n",
    "    _, axes = plt.subplots(1, 1, figsize=(10, 5))    \n",
    "    axes.set_title('Learning Curve')\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(scoring)\n",
    "\n",
    "    train_sizes, train_scores, test_scores= learning_curve(estimator,X,y,cv=cv,n_jobs=n_jobs,train_sizes=train_sizes,scoring = scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes,train_scores_mean - train_scores_std,train_scores_mean + train_scores_std,alpha=0.1,color=\"r\")\n",
    "    axes.fill_between(train_sizes,test_scores_mean - test_scores_std,test_scores_mean + test_scores_std,alpha=0.1,color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "#code to prevent warnings that can occur as a result of this function\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data resource VillanovaUniversityWeather.csv already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#download data files if not currently found in your datasets directory (under the current working directory)\n",
    "path = 'https://raw.githubusercontent.com/SueMcMetzger/MachineLearning/main/chpt15/'\n",
    "filename = \"VillanovaUniversityWeather.csv\"\n",
    "\n",
    "downloadDataResource(filename,path)\n",
    "\n",
    "#create a dataframe with the data from the CSV file\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the date information to a date value\n",
    "data['date'] = data['dt_iso'].apply(lambda x: x[0:20])\n",
    "data['date']= pd.to_datetime(data['date'], errors='coerce', format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary data (but feel free to add back in data if you wish\n",
    "data.drop(['dt_iso', 'rain_1h','rain_3h','snow_1h','snow_3h','temp_min','temp_max','clouds_all','weather_id','weather_main','weather_description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data (for performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data so we are only seeing the temperature at 1 given hour in the day\n",
    "#choose hour 5 which in EST time zone would be at mid-day\n",
    "#feel free to comment out this filter and you will have hourly data to anlayze (as opposed to daily)\n",
    "data = data[data['date'].dt.hour == 5]\n",
    "\n",
    "#OR limited data to 2 years worth - feel free to change this if you want to look at more years\n",
    "data = data[data['date'].dt.year > 2018 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns\n",
    "#data['hour'] = data.date.dt.hour  # NOT INCLUDING when we filter on hour (because column will have the same value)\n",
    "data['year'] = data.date.dt.year\n",
    "data['month'] = data.date.dt.month\n",
    "data['day'] = data.date.dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the date field as the index\n",
    "data.set_index('date',inplace = True)\n",
    "data.drop_duplicates(inplace=True)  #There appears to be some duplicates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 05:00:00</th>\n",
       "      <td>46.51</td>\n",
       "      <td>43.81</td>\n",
       "      <td>1008</td>\n",
       "      <td>100</td>\n",
       "      <td>3.36</td>\n",
       "      <td>200</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 05:00:00</th>\n",
       "      <td>40.37</td>\n",
       "      <td>34.30</td>\n",
       "      <td>1023</td>\n",
       "      <td>75</td>\n",
       "      <td>4.70</td>\n",
       "      <td>295</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 05:00:00</th>\n",
       "      <td>39.16</td>\n",
       "      <td>32.68</td>\n",
       "      <td>1007</td>\n",
       "      <td>86</td>\n",
       "      <td>6.08</td>\n",
       "      <td>160</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04 05:00:00</th>\n",
       "      <td>30.07</td>\n",
       "      <td>23.77</td>\n",
       "      <td>1011</td>\n",
       "      <td>100</td>\n",
       "      <td>4.36</td>\n",
       "      <td>247</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05 05:00:00</th>\n",
       "      <td>42.22</td>\n",
       "      <td>38.01</td>\n",
       "      <td>996</td>\n",
       "      <td>100</td>\n",
       "      <td>4.32</td>\n",
       "      <td>43</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      temp  feels_like  pressure  humidity  wind_speed  \\\n",
       "date                                                                     \n",
       "2019-01-01 05:00:00  46.51       43.81      1008       100        3.36   \n",
       "2019-01-02 05:00:00  40.37       34.30      1023        75        4.70   \n",
       "2019-01-03 05:00:00  39.16       32.68      1007        86        6.08   \n",
       "2019-01-04 05:00:00  30.07       23.77      1011       100        4.36   \n",
       "2019-01-05 05:00:00  42.22       38.01       996       100        4.32   \n",
       "\n",
       "                     wind_deg  year  month  day  \n",
       "date                                             \n",
       "2019-01-01 05:00:00       200  2019      1    1  \n",
       "2019-01-02 05:00:00       295  2019      1    2  \n",
       "2019-01-03 05:00:00       160  2019      1    3  \n",
       "2019-01-04 05:00:00       247  2019      1    4  \n",
       "2019-01-05 05:00:00        43  2019      1    5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at the first few instances\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save FUTURE data points to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FUTURE = 5\n",
    "\n",
    "#For demonstrations purposes, keep the predictions aside so you can evaluate the results\n",
    "toPredict = data[-FUTURE:].copy()\n",
    "y_predict = list(toPredict.temp)\n",
    "\n",
    "data = data[:-FUTURE].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the columns to create both the test and the training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((581, 8), (581,), (146, 8), (146,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=['temp']), \n",
    "    data.temp,\n",
    "    test_size=0.2,\n",
    "    random_state=32,\n",
    "    stratify = data.year\n",
    ")\n",
    "X_train.shape,  y_train.shape, X_test.shape,  y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no categorical attributes for this data set (nice to have in case data changes)\n",
    "cat_attribs = []\n",
    "\n",
    "#set the numerical attributes\n",
    "num_attribs = list( data.drop(columns=['temp']) )\n",
    "\n",
    "#define pipeline for numeric attributes (this code is just a definition)\n",
    "#each numeric attribute will be imputated using the Median strategy\n",
    "#each numeric attribute will be scaled \n",
    "num_pipeline = Pipeline( [\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")), #because no missing values, not used\n",
    "    ('std_scaler', StandardScaler()),   \n",
    "] )\n",
    "\n",
    "#define the pipeline process for the data set\n",
    "full_pipeline = ColumnTransformer( [\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(sparse=False), cat_attribs)      #because no categorical attributes, not used \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an array of prepared data based on the training data set\n",
    "X_train = full_pipeline.fit_transform( X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an array of prepared data based on the test data set\n",
    "X_test = full_pipeline.transform( X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 9 features, but ColumnTransformer is expecting 8 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8660/2753372802.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtoPredict\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         if (self._feature_names_in is not None and\n\u001b[0;32m    558\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 9 features, but ColumnTransformer is expecting 8 features as input."
     ]
    }
   ],
   "source": [
    "X_predict = full_pipeline.transform( toPredict )\n",
    "X_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Some Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Naive Forecasting</font>: just use the last observed value in the series to predict the next value in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the average home value\n",
    "baseline_prediction = y_train.mean()\n",
    "\n",
    "#populate an array with the average home value\n",
    "predictions = np.full(shape=len(X_train), fill_value = baseline_prediction)\n",
    "\n",
    "#determine the Root Mean Squared Error based on the actual vs. the baseline prediction\n",
    "baseline_rmse = mean_squared_error(y_train, predictions, squared=False)\n",
    "print(\"Baseline temp: {:,.2f}\".format(baseline_prediction))\n",
    "print(\"Baseline Performance (of this guess): {:,.2f}\".format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model object\n",
    "model = Ridge(alpha=0.5, solver='saga')\n",
    "\n",
    "#fit the model to the prepared test data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#calculate the predicted values\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "print(\"Prediction Error (RMSE): {:,.4f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cross valudation to process the data 10 different ways using linear regression model generated above\n",
    "#helps us to understand how well the model \"fits\" our data\n",
    "scores = cross_val_score(model, X_train, y_train,\n",
    "                         scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "#calculate the average score over the 10 different cross validations\n",
    "print(\"Average of RMSE across folds: {:,.4f}\".format(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predicted values for Test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "lin_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Test Prediction Error (RMSE): {:,.4f}\".format(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predicted values for Test\n",
    "y_pred = model.predict(X_predict)\n",
    "\n",
    "lin_rmse = mean_squared_error(y_predict, y_pred, squared=False)\n",
    "print(\"Test Prediction Error (RMSE): {:,.4f}\".format(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_pred(y_predict, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Stocahstic Gradiant Descent Regressor object\n",
    "model = SGDRegressor(max_iter=1000, tol=.01, penalty=\"l2\", eta0=.001)\n",
    "\n",
    "#fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#calcualte the predicted values\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "#compare the predicted to the actuals to evaluate the model\n",
    "rmse = mean_squared_error(y_train,predictions,squared=False)\n",
    "print(\"Predition Error (RMSE): {:,.4f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predicted values for Test\n",
    "y_pred =model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Test Prediction Error (RMSE): {:,.4f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predicted values for Test\n",
    "y_pred = model.predict(X_predict)\n",
    "\n",
    "rmse = mean_squared_error(y_predict, y_pred, squared=False)\n",
    "print(\"Test Prediction Error (RMSE): {:,.4f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_pred(y_predict, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
